# Лабораторная работа №5

## Датасет

Для решения задачи был выбран датасет MovieLens 100K ([ссылка](https://grouplens.org/datasets/movielens/100k/)), в котором содержится 100k оценок 1682 фильмов, поставленных 943 пользователями. Оценки представляют собой вещественные числа в диапазоне от 1 до 5.

## Описание алгоритма
Модель латентных векторов (Latent Factor Model, LFM) — это метод коллаборативной фильтрации, применяемый в рекомендательных систем и анализа данных. Он основан на представлении объектов (например, пользователей и объектов пользования) в виде векторов в скрытом (латентном) пространстве признаков.

## Реализация
При обучении модели (см. метод `fit`) для каждого пользователя и фильма считается предсказанный рейтинг путем умножения вектора латентных факторов пользователя на транспонированный вектор скрытых факторов фильма. Затем вычисляется отклонение предикта от реального рейтинга, использующееся далее для корректировки значений скрытых факторов. Значения изменяются путем прибавления или вычитания (в зависимости от знака ошибки) разности произведения ошибки на значения вектора л. факторов фильма/пользователя и члена регуляризации (произведения коэф. регуляризации на сам вектор).

```python
    def fit(self, data):
        for _ in range(self.n_epochs):
            for _, row in data.iterrows():
                u = row['user_idx']
                i = row['item_idx']
                r_ui = row['rating']
                pred = self.user_factors[u].dot(self.item_factors[i].T)
                error = r_ui - pred
                self.user_factors[u] += self.lr * (error * self.item_factors[i] - self.reg_coef * self.user_factors[u])
                self.item_factors[i] += self.lr * (error * self.user_factors[u] - self.reg_coef * self.item_factors[i])
```
## Сравнение с эталоном
### Метрики
RMSE кастомного алгоритма: 0.997 vs 0.986 scikit-surprise.
MAE кастомного алгоритма: 0.776 vs 0.767 у библиотечной реализации.

### Время обучения
Время обучения кастомного алгоритма: 212.475 с vs 1.209 с библиотечного алгоритма. 

## Выводы
Кастомная LFM опередила библиотечную реализацию scikit-surprise по значениям метрик, однако обучалась на два порядка дольше. Такая значительная разница во времени обучения может быть объяснена тем фактом, что реализация SVD scikit-surprise написана на Cython и куда более оптимизирована. 
