{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Libraries"
      ],
      "metadata": {
        "id": "vJOtOOAwiOww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y gensim numpy scipy"
      ],
      "metadata": {
        "id": "kMj9cUugvcRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==4.3.1 numpy==1.23.5 scipy==1.10.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ga6japtHubiP",
        "outputId": "9b5df134-5f9e-4c0e-9fe5-b795ab3db25f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim==4.3.1 in /usr/local/lib/python3.11/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.11/dist-packages (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.1) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim==4.3.1) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Yht8VBRzxxmH",
        "outputId": "c41e46bb-3b06-4680-a4db-ae68da9ffc26"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "metadata": {
        "id": "y6CQkA9ojOnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ca47a7-c3a6-4fac-e8f1-2181be508321"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load the Dataset"
      ],
      "metadata": {
        "id": "6YpU51rzi3in"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/movie_genre_classification_final.csv'\n",
        "dataset = pd.read_csv(path)\n",
        "print(\"Dataset Loaded:\\n\", dataset.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPw8zkjai8lA",
        "outputId": "c1b2592d-2d47-46c8-aa3e-303e194858ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded:\n",
            "              Title  Year  Director  Duration  Rating   Votes  \\\n",
            "0  Winds of Fate 4  1980    R. Lee       167     4.1  182425   \n",
            "1     Firestorm 11  2014   S. Chen       166     4.1  449351   \n",
            "2    Silent Echo 2  2016   A. Khan       170     4.1  363328   \n",
            "3    City Lights 4  1982  L. Zhang       170     9.9   62371   \n",
            "4   Broken Truth 1  1990  L. Zhang        91     5.3    4600   \n",
            "\n",
            "                                         Description  Language Country  \\\n",
            "0   A touching love story with heartwarming moments.   Spanish   China   \n",
            "1  A fast-paced thriller with intense action scenes.    Korean   China   \n",
            "2  A fast-paced thriller with intense action scenes.    Korean   Japan   \n",
            "3  An emotional journey exploring complex charact...  Japanese   Japan   \n",
            "4  An imaginative world filled with magic and won...    Korean     USA   \n",
            "\n",
            "   Budget_USD  BoxOffice_USD    Genre Production_Company Content_Rating  \\\n",
            "0    39979615      179936008  Romance         DreamWorks              R   \n",
            "1   116404774      802121619   Action            Netflix              R   \n",
            "2   166261330      225526871   Action              Pixar             PG   \n",
            "3    28861315       69813738    Drama            Netflix          NC-17   \n",
            "4    43890403      375136716  Fantasy      Studio Ghibli             PG   \n",
            "\n",
            "         Lead_Actor  Num_Awards  Critic_Reviews  \n",
            "0    Kangana Ranaut           8             229  \n",
            "1    Kangana Ranaut          20             466  \n",
            "2  Amitabh Bachchan          16             539  \n",
            "3   Natalie Portman          15             606  \n",
            "4       Chris Evans           6             330  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzhGJ-Cmjumh",
        "outputId": "d38fe80b-9129-4494-e572-cdcf7cb009c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "604Ylpkujxlv",
        "outputId": "653f1913-1cea-46c2-c59c-0a6881adbbe1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title                 0\n",
            "Year                  0\n",
            "Director              0\n",
            "Duration              0\n",
            "Rating                0\n",
            "Votes                 0\n",
            "Description           0\n",
            "Language              0\n",
            "Country               0\n",
            "Budget_USD            0\n",
            "BoxOffice_USD         0\n",
            "Genre                 0\n",
            "Production_Company    0\n",
            "Content_Rating        0\n",
            "Lead_Actor            0\n",
            "Num_Awards            0\n",
            "Critic_Reviews        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYjfun91jz63",
        "outputId": "82a2c28f-e4dc-4fb8-bff8-279bbccfd924"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title                  object\n",
            "Year                    int64\n",
            "Director               object\n",
            "Duration                int64\n",
            "Rating                float64\n",
            "Votes                   int64\n",
            "Description            object\n",
            "Language               object\n",
            "Country                object\n",
            "Budget_USD              int64\n",
            "BoxOffice_USD           int64\n",
            "Genre                  object\n",
            "Production_Company     object\n",
            "Content_Rating         object\n",
            "Lead_Actor             object\n",
            "Num_Awards              int64\n",
            "Critic_Reviews          int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preprocess the Dataset"
      ],
      "metadata": {
        "id": "C20SzpH1kDNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Preprocess descriptions\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = [\n",
        "        token.lemma_ for token in doc\n",
        "        if token.is_alpha and token.lemma_ not in stop_words and len(token) > 2\n",
        "    ]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "dataset['Cleaned_Description'] = dataset['Description'].astype(str).apply(clean_text)\n",
        "\n",
        "# Step 2: Split into features and labels\n",
        "X = dataset['Cleaned_Description']\n",
        "y = dataset['Genre']"
      ],
      "metadata": {
        "id": "BI1A-QzCoVkM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the vectorizer\n",
        "vectorizer = TfidfVectorizer(max_df=0.99, min_df=2)\n",
        "\n",
        "# Fit on training data only\n",
        "X = vectorizer.fit_transform(X)"
      ],
      "metadata": {
        "id": "6q0qt7aPrcKU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWDbUnLDssVc",
        "outputId": "0c29768d-7021-4861-bc61-4f3b5f5ac8c7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Romance' 'Action' 'Drama' 'Fantasy' 'Comedy' 'Thriller' 'Horror']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenized docs for coherence\n",
        "tokenized_docs = [doc.split() for doc in dataset.loc[y.index, 'Cleaned_Description']]\n",
        "\n",
        "# Gensim dictionary and corpus\n",
        "dictionary = Dictionary(tokenized_docs)\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_docs]"
      ],
      "metadata": {
        "id": "05_Zin-Xvz29"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Reference Latent Dirichlet Allocation (LDA)"
      ],
      "metadata": {
        "id": "tRqu8r2skdum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_topics = 7\n",
        "lda_ref = LatentDirichletAllocation(\n",
        "    n_components=n_topics,\n",
        "    max_iter=10,\n",
        "    learning_method='online',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "start_time = datetime.now()\n",
        "lda_ref.fit(X, y)\n",
        "end_time = datetime.now()\n",
        "\n",
        "execution_time = (end_time - start_time).microseconds\n",
        "print(f\"Execution Time: {execution_time} mcs\")"
      ],
      "metadata": {
        "id": "8byfqtuTmLsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d8817a-678f-4b63-da27-075cc54295f2"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 97765 mcs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topics(model, feature_names, n_top_words=10):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"\\nTopic #{topic_idx + 1}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
        "\n",
        "display_topics(lda_ref, vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg_8UZQUttcw",
        "outputId": "038fdfec-a09e-4f8f-9512-6ed261f44abf"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic #1:\n",
            "love touching moment heartwarming story fill guarantee laughter comedy hearted\n",
            "\n",
            "Topic #2:\n",
            "journey character explore complex emotional fill light laughter hearted comedy\n",
            "\n",
            "Topic #3:\n",
            "action thriller intense pace scene fast fill guarantee light laughter\n",
            "\n",
            "Topic #4:\n",
            "evoke fear tale spine chilling dread fill light comedy laughter\n",
            "\n",
            "Topic #5:\n",
            "unexpected twist suspenseful plot light hearted comedy laughter guarantee fill\n",
            "\n",
            "Topic #6:\n",
            "fill suspenseful twist unexpected plot guarantee hearted laughter comedy light\n",
            "\n",
            "Topic #7:\n",
            "world wonder magic imaginative fill twist unexpected plot suspenseful light\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract topics from scikit-learn LDA model\n",
        "def get_sklearn_topics(model, vectorizer, n_top_words=10):\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    topics = []\n",
        "    for topic_weights in model.components_:\n",
        "        top_features = [feature_names[i] for i in topic_weights.argsort()[:-n_top_words - 1:-1]]\n",
        "        topics.append(top_features)\n",
        "    return topics\n",
        "\n",
        "topics = get_sklearn_topics(lda_ref, vectorizer)"
      ],
      "metadata": {
        "id": "vX0xQm4av9nH"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute coherence score\n",
        "coherence_model = CoherenceModel(\n",
        "    topics=topics,\n",
        "    texts=tokenized_docs,\n",
        "    dictionary=dictionary,\n",
        "    coherence='c_v'\n",
        ")\n",
        "\n",
        "coherence_score = coherence_model.get_coherence()\n",
        "print(f\"Topic Coherence (c_v): {coherence_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s--cWr4wK1s",
        "outputId": "c7bc10ad-f3f6-4b49-bb9a-c0f6f22a69f6"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic Coherence (c_v): 0.2307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Custom Latent Dirichlet Allocation (LDA)"
      ],
      "metadata": {
        "id": "523siaxenC4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLatentDirichletAllocation:\n",
        "    def __init__(self, n_topics=7, alpha=0.1, beta=0.01, n_iter=100):\n",
        "        self.n_topics = n_topics\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.n_iter = n_iter\n",
        "\n",
        "    def fit(self, corpus, dictionary):\n",
        "        self.dictionary = dictionary\n",
        "        self.V = len(dictionary)\n",
        "        self.D = len(corpus)\n",
        "        self.Z = []  # topic assignments\n",
        "        self.n_dk = np.zeros((self.D, self.n_topics)) + self.alpha  # doc-topic\n",
        "        self.n_kw = np.zeros((self.n_topics, self.V)) + self.beta   # topic-word\n",
        "        self.n_k = np.zeros(self.n_topics) + self.V * self.beta     # total topic counts\n",
        "\n",
        "        # Randomly initialize topic assignments\n",
        "        for d, doc in enumerate(corpus):\n",
        "            z_current = []\n",
        "            for (word_id, count) in doc:\n",
        "                for _ in range(count):\n",
        "                    topic = random.randint(0, self.n_topics - 1)\n",
        "                    z_current.append(topic)\n",
        "                    self.n_dk[d, topic] += 1\n",
        "                    self.n_kw[topic, word_id] += 1\n",
        "                    self.n_k[topic] += 1\n",
        "            self.Z.append(z_current)\n",
        "\n",
        "        # Begin Gibbs sampling\n",
        "        for it in tqdm(range(self.n_iter), desc=\"Training Custom LDA\"):\n",
        "            for d, doc in enumerate(corpus):\n",
        "                word_pos = 0\n",
        "                for word_id, count in doc:\n",
        "                    for _ in range(count):\n",
        "                        topic = self.Z[d][word_pos]\n",
        "\n",
        "                        # Decrease counts\n",
        "                        self.n_dk[d, topic] -= 1\n",
        "                        self.n_kw[topic, word_id] -= 1\n",
        "                        self.n_k[topic] -= 1\n",
        "\n",
        "                        # Sample new topic\n",
        "                        p_z = (self.n_kw[:, word_id] / self.n_k) * (self.n_dk[d])\n",
        "                        p_z /= np.sum(p_z)\n",
        "                        new_topic = np.random.choice(self.n_topics, p=p_z)\n",
        "\n",
        "                        # Update\n",
        "                        self.Z[d][word_pos] = new_topic\n",
        "                        self.n_dk[d, new_topic] += 1\n",
        "                        self.n_kw[new_topic, word_id] += 1\n",
        "                        self.n_k[new_topic] += 1\n",
        "\n",
        "                        word_pos += 1\n",
        "\n",
        "    def get_topics(self, top_n=10):\n",
        "        topics = []\n",
        "        for k in range(self.n_topics):\n",
        "            top_word_ids = self.n_kw[k].argsort()[::-1][:top_n]\n",
        "            topic_words = [self.dictionary[i] for i in top_word_ids]\n",
        "            topics.append(topic_words)\n",
        "        return topics"
      ],
      "metadata": {
        "id": "dhAoW95QAFWY"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_topics = 7\n",
        "lda_cus = CustomLatentDirichletAllocation(n_topics=n_topics, n_iter=100)\n",
        "\n",
        "start_time = datetime.now()\n",
        "lda_cus.fit(corpus, dictionary)\n",
        "end_time = datetime.now()\n",
        "\n",
        "execution_time = (end_time - start_time).microseconds\n",
        "print(f\"\\nExecution Time: {execution_time} mcs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O4V9qwPAWCG",
        "outputId": "f86ba36f-5b69-4f6a-c4cc-b68e4b0d103e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Custom LDA: 100%|██████████| 100/100 [15:25<00:00,  9.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Execution Time: 847394 mcs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_topics = lda_cus.get_topics(top_n=10)\n",
        "\n",
        "# Display topics\n",
        "for i, topic in enumerate(custom_topics, 1):\n",
        "    print(f\"\\nTopic #{i}: {' '.join(topic)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jo32QU1CL7e",
        "outputId": "4cc1cce4-c95f-4247-c139-d7d1977a65ef"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic #1: laughter light comedy guarantee hearted fill magic wonder world imaginative\n",
            "\n",
            "Topic #2: fast intense scene thriller pace action fill touching story spine\n",
            "\n",
            "Topic #3: tale spine fear evoke dread chilling love moment story touching\n",
            "\n",
            "Topic #4: journey explore emotional complex character heartwarming love moment story touching\n",
            "\n",
            "Topic #5: fill unexpected twist suspenseful plot intense emotional complex character thriller\n",
            "\n",
            "Topic #6: action pace thriller scene intense fast fill touching story spine\n",
            "\n",
            "Topic #7: imaginative world fill magic wonder spine tale chilling dread evoke\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coherence_custom = CoherenceModel(\n",
        "    topics=custom_topics,\n",
        "    texts=tokenized_docs,\n",
        "    dictionary=dictionary,\n",
        "    coherence='c_v'\n",
        ").get_coherence()\n",
        "\n",
        "print(f\"\\nCustom LDA Topic Coherence (c_v): {coherence_custom:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-gCHPjyDv-F",
        "outputId": "cdbadb46-2dec-4d63-fdd5-278aa7d80555"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Custom LDA Topic Coherence (c_v): 0.2269\n"
          ]
        }
      ]
    }
  ]
}