# Лабораторная работа №1. Ансамбли моделей

## Описание проекта
В этой работе реализован и исследован один из ансамблевых методов — **бэггинг** на базе решающих деревьев — и проведено сравнение с:  
1. Одиночным `DecisionTreeClassifier`  
2. Библиотечной реализацией `RandomForestClassifier` из `scikit-learn`

В качестве данных используется **Glass Classification** датасет.

## Описание метода
**Бэггинг** (Bootstrap AGGregatING) — метод повышения стабильности и точности моделей путём обучения нескольких базовых алгоритмов на разных бутстрэп-подвыборках исходных данных.
- **Bootstrap-подвыборки**: для каждого из \(n\_estimators\) деревьев создаётся выборка из \(m\) объектов (с возвращением).
- **Random Subspace**: при каждом разбиении дерева выбирается случайное подмножество признаков (обычно \(\sqrt{p}\), где \(p\) — число признаков).
- **Агрегация**: прогнозы объединяются **мажоритарным голосованием**.

## Описание датасета
**Glass Classification**:
- **Источник**: UCI ML Repository  
- **Записи**: 214  
- **Признаки (9)**: RI, Na, Mg, Al, Si, K, Ca, Ba, Fe  
- **Классы (6)**: типы стекла  
- **Кодирование меток**: `LabelEncoder`

## Результаты
```
=== Hand-made Bagging ===
Accuracy hand method: 0.8148
Recall   hand method: 0.6116
Precision hand method: 0.7364
Time: 0.39 s

=== Single Decision Tree ===
Accuracy: 0.7037
Recall:   0.6233
Precision:0.6660
Time: 0.01 s

=== sklearn RandomForest ===
Accuracy: 0.7778
Recall:   0.6399
Precision:0.6708
Time: 0.37 s
```

---

## Выводы
- Собственная реализация бэггинга показала наивысшую точность (≈0.815), но уступает по времени обучению `DecisionTree` и `RandomForest`.  
- `RandomForestClassifier` даёт почти те же метрики, что и ручной бэггинг, но работает быстрее благодаря оптимизациям C и параллелизму.

