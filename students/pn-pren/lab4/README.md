# Лабораторная работа 4: Латентное размещение Дирихле (LDA)

## Описание алгоритма латентного размещения Дирихле

Латентное размещение Дирихле (Latent Dirichlet Allocation, LDA) — это байесовская модель для тематического моделирования текстовых документов. Алгоритм основан на предположении, что каждый документ представляет собой смесь тем, а каждая тема — это распределение по словам.

### Основные компоненты модели:

1. **Параметры модели:**
   - `α` (alpha) — параметр концентрации для распределения тем в документах
   - `β` (beta) — параметр концентрации для распределения слов в темах
   - `K` — количество тем

2. **Основные матрицы:**
   - `θ` (theta) — матрица распределений тем по документам (D × K)
   - `φ` (phi) — матрица распределений слов по темам (K × V)

3. **Алгоритм обучения (EM-алгоритм):**
   - **E-шаг:** Вычисление апостериорных вероятностей p(t|d,w) для каждой тройки (документ, слово, тема)
   - **M-шаг:** Обновление параметров θ и φ на основе вычисленных вероятностей

## Описание датасета

В эксперименте использовался датасет 20 Newsgroups — классический датасет для задач классификации и тематического моделирования текстов.

### Характеристики датасета:
- **Источник:** sklearn.datasets.fetch_20newsgroups
- **Выбранные категории:** 4 категории
  - `alt.atheism` — дискуссии об атеизме
  - `soc.religion.christian` — христианские религиозные дискуссии  
  - `comp.graphics` — компьютерная графика
  - `sci.med` — медицинские научные обсуждения

### Предобработка данных:
- Удаление email-адресов
- Удаление знаков препинания
- Приведение к нижнему регистру
- Удаление стоп-слов
- Векторизация с помощью CountVectorizer:
  - `max_df=0.95` — исключение слишком частых слов
  - `min_df=2` — исключение редких слов
  - `max_features=1000` — ограничение словаря

## Результаты экспериментов

### Параметры эксперимента:
- **Количество тем:** 4
- **Количество итераций:** 100
- **Топ слов на тему:** 10
- **Alpha:** 0.1
- **Beta:** 0.01

### Результаты собственной реализации LDA:
- **Время обучения:** 494.23 сек
- **Когерентность:** 0.4115
- **Выделенные темы:** 4 тематические группы слов

### Результаты scikit-learn LDA:
- **Время обучения:** 106.08 сек  
- **Когерентность:** 0.6927
- **Выделенные темы:** 4 тематические группы слов

### Оценка качества:
Для оценки качества тематических моделей использовалась метрика когерентности, которая измеряет семантическую связность слов внутри каждой темы.

## Сравнение с эталонной реализацией

### Архитектурные различия:
1. **Собственная реализация:**
   - Простая реализация EM-алгоритма
   - Использование numpy для матричных операций
   - Прямое обновление параметров θ и φ

2. **Scikit-learn реализация:**
   - Более эффективные алгоритмы оптимизации

### Сравнение производительности:
- **Время выполнения:** Scikit-learn значительно быстрее благодаря оптимизации
- **Качество результатов:** Scikit-learn значительно превосходит кастомную реализацию по когерентности

### Качество тем:
Обе реализации успешно выделяют осмысленные темы, соответствующие исходным категориям новостных групп:
- Религиозные темы (atheism, christian)
- Технические темы (graphics, medical)

## Выводы

1. **Успешность реализации:** Собственная реализация LDA показала работоспособность и способность выделять осмысленные темы из текстовых данных, но требует оптимизации для ускорения работы и повышения точности.

2. **Производительность:** Эталонная реализация scikit-learn значительно превосходит по скорости выполнения, что объясняется использованием оптимизированных библиотек и алгоритмов.

3. **Области улучшения:**
   - Добавление проверки сходимости
   - Оптимизация вычислений для больших датасетов
   - Реализация других методов инференса (например, Gibbs sampling)