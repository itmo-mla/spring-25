# Отчет по лабораторной работе

## Описание выбранного метода
**Bagging** - ансамблевый метод машинного обучения, направленный на снижение дисперсии модели и улучшение обобщающей способности за счёт объединения предсказаний нескольких базовых моделей, обученных на различных выборках, полученных с помощью бутстрэпа. Каждый базовый классификатор обучается на своей бутстрап-выборке. Итоговое решение принимается голосованием большинства. В качестве базового классификатора использовано решающее дерево.

## Описание датасета Wine Quality Dataset
### Источник
https://www.kaggle.com/datasets/yasserh/wine-quality-dataset

### Размер
1143 образца

### Целевая переменная
Качество вина (преобразована в 3 класса)

### Предобработка данных
- Удален неинформативный признак Id
- Применена обработка выбросов и масштабирование признаков
- Устранена мультиколлинеарности (удален признак total sulfur dioxide)
- Применено балансировка классов с помощью SMOTE ддя обучающей выборки

## Результаты экспериментов
### Средняя точность по кросс-валидации: 1.0000 (+/- 0.0000)
### Точность на тестовой выборке: 1.0000

### Cравнение с эталонными реализациями
- Самописная версия обучилась быстрее (Custom 0.0900 против Sklearn 0.1299)
- Точность одинаковая

## Выводы
- Модель успешно справляется с задачей классификации качества вина
- Балансировка классов помогла улучшить качество предсказаний для миноритарных классов
- Собственная реализация показывает сопоставимые результаты с sklearn